{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taker\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "import math, os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング用の入力データの選択\n",
    "X_columns = ['locality', 'age', 'rank', 'leg', 'racing piont', \\\n",
    "             'S', 'B', 'Nige', 'Maki', 'Sashi', 'Ma', \\\n",
    "             '1st', '2nd', '3rd', 'Chakugai', 'win', '2ren', '3ren']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webスクレイピングで取得した戦績データをファイルから読み取り、データフレームに変換＋データ前処理\n",
    "def get_df_train(places):\n",
    "    \n",
    "    init_flag = True\n",
    "    for place in places:\n",
    "        print('loading data for ' + place)\n",
    "        filename = \"data/\" + place + \"_train_data.csv\"\n",
    "        df_train = pd.read_csv(filename, encoding=\"SHIFT_JIS\", header=0, nrows=None)\n",
    "\n",
    "        targets = []\n",
    "        name_ids = []\n",
    "        localities = []\n",
    "\n",
    "        for index, row in df_train.iterrows():\n",
    "\n",
    "            # 1位を予想するため One-Hot表現にする\n",
    "            result = row['result']\n",
    "            if result == 1:\n",
    "                target = 1\n",
    "            else:\n",
    "                target = 0\n",
    "            targets.append(target)    \n",
    "\n",
    "            # 名前をハッシュを使ってID化\n",
    "            name = row['name']\n",
    "            name_hash = hashlib.md5(name.encode()).hexdigest()\n",
    "            name_id = name_hash[-8:]\n",
    "            name_ids.append(name_id)\n",
    "\n",
    "            # 　ランクの例外処理\n",
    "            if row['rank'] == 'SS':\n",
    "                df_train.loc[index, 'rank'] = '0'\n",
    "            elif row['rank'] == 'L1':\n",
    "                df_train.loc[index, 'rank'] = '6'\n",
    "\n",
    "            # 出身地を地区毎にグループ化\n",
    "            prefecture = row['prefecture']\n",
    "            if prefecture in {'1', '2', '3', '5'}:\n",
    "                locality = '1' #北東北\n",
    "            elif prefecture in {'4', '6', '7'}:\n",
    "                locality = '2' #南東北\n",
    "            elif prefecture in {'8', '9'}:\n",
    "                locality = '3' #茨栃\n",
    "            elif prefecture in {'11', '13'}:\n",
    "                locality = '4' #埼京\n",
    "            elif prefecture in {'10', '15', '19', '20'}:\n",
    "                locality = '5' #上信越\n",
    "            elif prefecture in {'12', '14', '22'}:\n",
    "                locality = '6' #南関東\n",
    "            elif prefecture in {'16', '17', '21', '23', '24'}:\n",
    "                locality = '7' #中部\n",
    "            elif prefecture in {'18', '25', '26', '27', '28', '29', '30'}:\n",
    "                locality = '8' #近畿\n",
    "            elif prefecture in {'31', '32', '33', '34', '35'}:\n",
    "                locality = '9' #中国\n",
    "            elif prefecture in {'36', '37', '38', '39'}:\n",
    "                locality = '10' #四国\n",
    "            elif prefecture in {'40', '41', '42', '43', '44', '45', '46', '47'}:\n",
    "                locality = '11' #九州\n",
    "            else:\n",
    "                locality = '12' #外国\n",
    "\n",
    "            localities.append(locality)\n",
    "\n",
    "        # 前処理したデータのデータフレームへの置き換え\n",
    "        df_train['target'] = targets\n",
    "        df_train['name_id'] = name_ids\n",
    "        df_train['locality'] = localities\n",
    "\n",
    "        # カラムの順番入れ替え（見やすさのため）\n",
    "        columns = list(df_train.columns)\n",
    "        columns.remove('name_id')\n",
    "        columns.insert(columns.index(\"name\") + 1, \"name_id\")\n",
    "        columns.remove('locality')\n",
    "        columns.insert(columns.index(\"prefecture\") + 1, \"locality\")\n",
    "\n",
    "        df_train = df_train.loc[:,columns]\n",
    "        \n",
    "        if init_flag:\n",
    "            df_train_concat = df_train\n",
    "            init_flag = False\n",
    "        else:\n",
    "            df_train_concat = pd.concat([df_train_concat, df_train])\n",
    "    \n",
    "    return df_train_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(df_train):\n",
    "    X = []\n",
    "    target = []\n",
    "        \n",
    "    # 各レース毎に\n",
    "    grouped = df_train.groupby(['date', 'place', 'race_num'])\n",
    "    for race_name, group in tqdm(grouped):\n",
    "        #print(race_name)\n",
    "        racer_count = group.shape[0]\n",
    "        # もし、９輪ではないレースは、トレーニングの対象から外す（モデルを固めるため）\n",
    "        if racer_count != 9:\n",
    "            continue\n",
    "        X.append(group[X_columns].values)\n",
    "        target.append(group['target'].values)\n",
    "\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
    "    d_ = np.array(target)\n",
    "\n",
    "    X_train, X_test, d_train, d_test = train_test_split(X, d_, test_size = 0.2)\n",
    "\n",
    "    return X_train, X_test, d_train, d_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(object):\n",
    "    def __init__(self, n_in, n_hiddens, n_out):\n",
    "        self.n_in = n_in\n",
    "        self.n_hiddens = n_hiddens\n",
    "        self.n_out = n_out\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        self._x = None\n",
    "        self._y = None\n",
    "        self._t = None,\n",
    "        self._keep_prob = None\n",
    "        self._sess = None\n",
    "        self._history = {\n",
    "            'accuracy': [],\n",
    "            'loss': []\n",
    "        }\n",
    "\n",
    "    def weight_variable(self, shape):\n",
    "        # He 初期化\n",
    "        n_sum = 1\n",
    "        for n in shape:\n",
    "            n_sum *= n\n",
    "        stddev = math.sqrt(2.0 / n_sum)\n",
    "        print('stddev: ', stddev)\n",
    "        initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(self, shape):\n",
    "        initial = tf.zeros(shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def inference(self, x, keep_prob):\n",
    "        # 入力層 - 隠れ層、隠れ層 - 隠れ層\n",
    "        for i, n_hidden in enumerate(self.n_hiddens):\n",
    "            if i == 0:\n",
    "                input = x\n",
    "                input_dim = self.n_in\n",
    "            else:\n",
    "                input = output\n",
    "                input_dim = self.n_hiddens[i-1]\n",
    "\n",
    "            self.weights.append(self.weight_variable([input_dim, n_hidden]))\n",
    "            self.biases.append(self.bias_variable([n_hidden]))\n",
    "\n",
    "            input = tf.layers.batch_normalization(input)\n",
    "            h = tf.nn.relu(tf.matmul(input, self.weights[-1]) + self.biases[-1])\n",
    "            output = tf.nn.dropout(h, keep_prob)\n",
    "\n",
    "        # 隠れ層 - 出力層\n",
    "        self.weights.append(self.weight_variable([self.n_hiddens[-1], self.n_out]))\n",
    "        self.biases.append(self.bias_variable([self.n_out]))\n",
    "\n",
    "        y = tf.nn.softmax(tf.matmul(output, self.weights[-1]) + self.biases[-1])\n",
    "        \n",
    "        return y\n",
    "\n",
    "    def loss(self, y, t):\n",
    "        # クロスエントロピー  Nan 問題回避のためのコードに変更\n",
    "        #cross_entropy = tf.reduce_mean(-tf.reduce_sum(t * tf.log(y), axis=1))\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=t, logits=y))\n",
    "        #return cross_entropy\n",
    "        # L2 正則化\n",
    "        l2_decay = 0.0001\n",
    "        l2_losses = [tf.nn.l2_loss(w) for w in self.weights]\n",
    "        l2_loss = l2_decay * tf.add_n(l2_losses)\n",
    "        loss = cross_entropy + l2_loss\n",
    "        return loss\n",
    "\n",
    "    def training(self, loss):\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_step = optimizer.minimize(loss)\n",
    "        return train_step\n",
    "\n",
    "    def accuracy(self, y, t):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        return accuracy\n",
    "\n",
    "    def fit(self, X_train, Y_train, nb_epoch=100, batch_size=100, p_keep=0.5, verbose=1):\n",
    "        x = tf.placeholder(tf.float32, shape=[None, self.n_in])\n",
    "        t = tf.placeholder(tf.float32, shape=[None, self.n_out])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        self._x = x\n",
    "        self._t = t\n",
    "        self._keep_prob = keep_prob\n",
    "\n",
    "        y = self.inference(x, keep_prob)\n",
    "        loss = self.loss(y, t)\n",
    "        train_step = self.training(loss)\n",
    "        accuracy = self.accuracy(y, t)\n",
    "\n",
    "        sess = tf.Session()\n",
    "        \n",
    "        # TensorBoardで追跡する変数を定義\n",
    "        with tf.name_scope('summary'):\n",
    "            tf.summary.scalar('loss', loss)\n",
    "            merged = tf.summary.merge_all()\n",
    "            writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        writer.close()\n",
    "        \n",
    "        self._y = y\n",
    "        self._sess = sess\n",
    "\n",
    "        N_train = len(X_train)\n",
    "        n_batches = N_train // batch_size\n",
    "\n",
    "        for epoch in range(nb_epoch):\n",
    "            X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "            for i in range(n_batches):\n",
    "                start = i * batch_size\n",
    "                end = start + batch_size\n",
    "\n",
    "                sess.run(train_step, feed_dict={\n",
    "                    x: X_[start:end],\n",
    "                    t: Y_[start:end],\n",
    "                    keep_prob: p_keep\n",
    "                })\n",
    "            loss_ = loss.eval(session=sess, feed_dict={\n",
    "                x: X_train,\n",
    "                t: Y_train,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "            accuracy_ = accuracy.eval(session=sess, feed_dict={\n",
    "                x: X_train,\n",
    "                t: Y_train,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "            self._history['loss'].append(loss_)\n",
    "            self._history['accuracy'].append(accuracy_)\n",
    "\n",
    "            if verbose:\n",
    "                print('epoch:', epoch,\n",
    "                      ' loss:', loss_,\n",
    "                      ' accuracy:', accuracy_)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, \"model/training_model\")\n",
    "                \n",
    "        return self._history\n",
    "\n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        accuracy = self.accuracy(self._y, self._t)\n",
    "        return accuracy.eval(session=self._sess, feed_dict={\n",
    "            self._x: X_test,\n",
    "            self._t: Y_test,\n",
    "            self._keep_prob: 1.0\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax2 = ax1.twinx()  # 2つのプロットを関連付ける\n",
    "\n",
    "    ax1.plot(history['loss'], label='loss', color='orange')\n",
    "    ax1.set_ylabel('loss')\n",
    "    ax1.set_ylim(0, 2.5)\n",
    "    ax1.legend(loc='best', bbox_to_anchor=(1.01, 0.71, 0.322, .100), borderaxespad=0.,)\n",
    "\n",
    "    ax2.plot(history['accuracy'], label='accuracy', color='dodgerblue')\n",
    "    ax2.set_ylabel('accuracy')\n",
    "    ax2.set_ylim(0, 1.0)\n",
    "    ax2.legend(loc='best', bbox_to_anchor=(1.01, 0.8, 0.4, .100), borderaxespad=0.,)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = []\n",
    "for filename in os.listdir('data/'):\n",
    "    place = filename.split('_')[0]\n",
    "    places.append(place)\n",
    "print(places)\n",
    "\n",
    "# クロスエントロピーが Nan になる場所を除外 (いわき平、熊本)\n",
    "places.remove('iwakitaira')\n",
    "places.remove('kumamoto')\n",
    "\n",
    "df_train = get_df_train(places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 th Loop\n",
      "Generating Training/Test Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/118 [00:00<?, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 118/118 [00:00<00:00, 1765.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "stddev:  0.006944444444444444\n",
      "stddev:  0.005524271728019903\n",
      "stddev:  0.02946278254943948\n",
      "epoch: 0  loss: 2.146829  accuracy: 0.28985506\n",
      "epoch: 1  loss: 2.0791767  accuracy: 0.28985506\n",
      "epoch: 2  loss: 2.0798512  accuracy: 0.28985506\n",
      "epoch: 3  loss: 2.082273  accuracy: 0.28985506\n",
      "epoch: 4  loss: 2.0823588  accuracy: 0.28985506\n",
      "epoch: 5  loss: 2.0823753  accuracy: 0.28985506\n",
      "epoch: 6  loss: 2.0823882  accuracy: 0.28985506\n",
      "epoch: 7  loss: 2.082399  accuracy: 0.28985506\n",
      "epoch: 8  loss: 2.082408  accuracy: 0.28985506\n",
      "epoch: 9  loss: 2.0824149  accuracy: 0.28985506\n",
      "epoch: 10  loss: 2.0824203  accuracy: 0.28985506\n",
      "epoch: 11  loss: 2.0824246  accuracy: 0.28985506\n",
      "epoch: 12  loss: 2.0824277  accuracy: 0.28985506\n",
      "epoch: 13  loss: 2.0824301  accuracy: 0.28985506\n",
      "epoch: 14  loss: 2.0824318  accuracy: 0.28985506\n",
      "epoch: 15  loss: 2.082433  accuracy: 0.28985506\n",
      "epoch: 16  loss: 2.0824337  accuracy: 0.28985506\n",
      "epoch: 17  loss: 2.082434  accuracy: 0.28985506\n",
      "epoch: 18  loss: 2.082434  accuracy: 0.28985506\n",
      "epoch: 19  loss: 2.0824337  accuracy: 0.28985506\n",
      "epoch: 20  loss: 2.082433  accuracy: 0.28985506\n",
      "epoch: 21  loss: 2.0824323  accuracy: 0.28985506\n",
      "epoch: 22  loss: 2.0824316  accuracy: 0.28985506\n",
      "epoch: 23  loss: 2.0824304  accuracy: 0.28985506\n",
      "epoch: 24  loss: 2.0824292  accuracy: 0.28985506\n",
      "epoch: 25  loss: 2.082428  accuracy: 0.28985506\n",
      "epoch: 26  loss: 2.0824268  accuracy: 0.28985506\n",
      "epoch: 27  loss: 2.0824254  accuracy: 0.28985506\n",
      "epoch: 28  loss: 2.0824242  accuracy: 0.28985506\n",
      "epoch: 29  loss: 2.0824227  accuracy: 0.28985506\n",
      "epoch: 30  loss: 2.0824213  accuracy: 0.28985506\n",
      "epoch: 31  loss: 2.0824199  accuracy: 0.28985506\n",
      "epoch: 32  loss: 2.0824184  accuracy: 0.28985506\n",
      "epoch: 33  loss: 2.082417  accuracy: 0.28985506\n",
      "epoch: 34  loss: 2.0824156  accuracy: 0.28985506\n",
      "epoch: 35  loss: 2.082414  accuracy: 0.28985506\n",
      "epoch: 36  loss: 2.0824125  accuracy: 0.28985506\n",
      "epoch: 37  loss: 2.082411  accuracy: 0.28985506\n",
      "epoch: 38  loss: 2.0824096  accuracy: 0.28985506\n",
      "epoch: 39  loss: 2.0824082  accuracy: 0.28985506\n",
      "epoch: 40  loss: 2.0824068  accuracy: 0.28985506\n",
      "epoch: 41  loss: 2.0824053  accuracy: 0.28985506\n",
      "epoch: 42  loss: 2.082404  accuracy: 0.28985506\n",
      "epoch: 43  loss: 2.0824027  accuracy: 0.28985506\n",
      "epoch: 44  loss: 2.0824013  accuracy: 0.28985506\n",
      "epoch: 45  loss: 2.0823998  accuracy: 0.28985506\n",
      "epoch: 46  loss: 2.0823984  accuracy: 0.28985506\n",
      "epoch: 47  loss: 2.0823972  accuracy: 0.28985506\n",
      "epoch: 48  loss: 2.0823958  accuracy: 0.28985506\n",
      "epoch: 49  loss: 2.0823946  accuracy: 0.28985506\n",
      "epoch: 50  loss: 2.0823932  accuracy: 0.28985506\n",
      "epoch: 51  loss: 2.0823917  accuracy: 0.28985506\n",
      "epoch: 52  loss: 2.0823905  accuracy: 0.28985506\n",
      "epoch: 53  loss: 2.0823894  accuracy: 0.28985506\n",
      "epoch: 54  loss: 2.082388  accuracy: 0.28985506\n",
      "epoch: 55  loss: 2.0823867  accuracy: 0.28985506\n",
      "epoch: 56  loss: 2.0823855  accuracy: 0.28985506\n",
      "epoch: 57  loss: 2.082384  accuracy: 0.28985506\n",
      "epoch: 58  loss: 2.082383  accuracy: 0.28985506\n",
      "epoch: 59  loss: 2.0823817  accuracy: 0.28985506\n",
      "epoch: 60  loss: 2.0823805  accuracy: 0.28985506\n",
      "epoch: 61  loss: 2.0823793  accuracy: 0.28985506\n",
      "epoch: 62  loss: 2.0823781  accuracy: 0.28985506\n",
      "epoch: 63  loss: 2.082377  accuracy: 0.28985506\n",
      "epoch: 64  loss: 2.0823758  accuracy: 0.28985506\n",
      "epoch: 65  loss: 2.0823746  accuracy: 0.28985506\n",
      "epoch: 66  loss: 2.0823734  accuracy: 0.28985506\n",
      "epoch: 67  loss: 2.0823722  accuracy: 0.28985506\n",
      "epoch: 68  loss: 2.082371  accuracy: 0.28985506\n",
      "epoch: 69  loss: 2.08237  accuracy: 0.28985506\n",
      "epoch: 70  loss: 2.0823689  accuracy: 0.28985506\n",
      "epoch: 71  loss: 2.0823677  accuracy: 0.28985506\n",
      "epoch: 72  loss: 2.0823667  accuracy: 0.28985506\n",
      "epoch: 73  loss: 2.0823655  accuracy: 0.28985506\n",
      "epoch: 74  loss: 2.0823643  accuracy: 0.28985506\n",
      "epoch: 75  loss: 2.0823634  accuracy: 0.28985506\n",
      "epoch: 76  loss: 2.0823622  accuracy: 0.28985506\n",
      "epoch: 77  loss: 2.0823612  accuracy: 0.28985506\n",
      "epoch: 78  loss: 2.08236  accuracy: 0.28985506\n",
      "epoch: 79  loss: 2.082359  accuracy: 0.28985506\n",
      "epoch: 80  loss: 2.082358  accuracy: 0.28985506\n",
      "epoch: 81  loss: 2.082357  accuracy: 0.28985506\n",
      "epoch: 82  loss: 2.082356  accuracy: 0.28985506\n",
      "epoch: 83  loss: 2.0823548  accuracy: 0.28985506\n",
      "epoch: 84  loss: 2.0823538  accuracy: 0.28985506\n",
      "epoch: 85  loss: 2.0823529  accuracy: 0.28985506\n",
      "epoch: 86  loss: 2.0823517  accuracy: 0.28985506\n",
      "epoch: 87  loss: 2.0823507  accuracy: 0.28985506\n",
      "epoch: 88  loss: 2.0823498  accuracy: 0.28985506\n",
      "epoch: 89  loss: 2.0823488  accuracy: 0.28985506\n",
      "epoch: 90  loss: 2.0823479  accuracy: 0.28985506\n",
      "epoch: 91  loss: 2.082347  accuracy: 0.28985506\n",
      "epoch: 92  loss: 2.082346  accuracy: 0.28985506\n",
      "epoch: 93  loss: 2.082345  accuracy: 0.28985506\n",
      "epoch: 94  loss: 2.082344  accuracy: 0.28985506\n",
      "epoch: 95  loss: 2.082343  accuracy: 0.28985506\n",
      "epoch: 96  loss: 2.0823421  accuracy: 0.28985506\n",
      "epoch: 97  loss: 2.0823412  accuracy: 0.28985506\n",
      "epoch: 98  loss: 2.0823402  accuracy: 0.28985506\n",
      "epoch: 99  loss: 2.0823393  accuracy: 0.28985506\n",
      "epoch: 100  loss: 2.0823383  accuracy: 0.28985506\n",
      "epoch: 101  loss: 2.0823374  accuracy: 0.28985506\n",
      "epoch: 102  loss: 2.0823364  accuracy: 0.28985506\n",
      "epoch: 103  loss: 2.0823357  accuracy: 0.28985506\n",
      "epoch: 104  loss: 2.0823348  accuracy: 0.28985506\n",
      "epoch: 105  loss: 2.0823338  accuracy: 0.28985506\n",
      "epoch: 106  loss: 2.0823328  accuracy: 0.28985506\n",
      "epoch: 107  loss: 2.0823321  accuracy: 0.28985506\n",
      "epoch: 108  loss: 2.0823312  accuracy: 0.28985506\n",
      "epoch: 109  loss: 2.0823302  accuracy: 0.28985506\n",
      "epoch: 110  loss: 2.0823295  accuracy: 0.28985506\n",
      "epoch: 111  loss: 2.0823286  accuracy: 0.28985506\n",
      "epoch: 112  loss: 2.0823278  accuracy: 0.28985506\n",
      "epoch: 113  loss: 2.082327  accuracy: 0.28985506\n",
      "epoch: 114  loss: 2.082326  accuracy: 0.28985506\n",
      "epoch: 115  loss: 2.0823252  accuracy: 0.28985506\n",
      "epoch: 116  loss: 2.0823243  accuracy: 0.28985506\n",
      "epoch: 117  loss: 2.0823236  accuracy: 0.28985506\n",
      "epoch: 118  loss: 2.0823228  accuracy: 0.28985506\n",
      "epoch: 119  loss: 2.082322  accuracy: 0.28985506\n",
      "accuracy:  0.16666667\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for loop in range(10):\n",
    "    print(loop+1, \"th Loop\")\n",
    "    print(\"Generating Training/Test Data\")\n",
    "    X_train, X_test, Y_train, Y_test = get_train_test_data(df_train)\n",
    "    \n",
    "    if loop == 0:\n",
    "        model = DNN(n_in = len(X_train[1]), n_hiddens=[256, 256], n_out=9)\n",
    "\n",
    "    print(\"Training ...\")\n",
    "    history = model.fit(X_train, Y_train, nb_epoch = 120, batch_size=32, p_keep=0.5)\n",
    "\n",
    "    accuracy = model.evaluate(X_test, Y_test)\n",
    "    print('accuracy: ', accuracy)\n",
    "    plot(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
