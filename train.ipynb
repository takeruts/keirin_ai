{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "import math, os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング用の入力データの選択\n",
    "X_columns = ['locality', 'age', 'rank', 'leg', 'racing piont', \\\n",
    "             'S', 'B', 'Nige', 'Maki', 'Sashi', 'Ma', \\\n",
    "             '1st', '2nd', '3rd', 'Chakugai', 'win', '2ren', '3ren']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webスクレイピングで取得した戦績データをファイルから読み取り、データフレームに変換＋データ前処理\n",
    "def get_df_train(places):\n",
    "    \n",
    "    init_flag = True\n",
    "    for place in places:\n",
    "        print('loading data for ' + place)\n",
    "        filename = \"data/\" + place + \"_train_data.csv\"\n",
    "        df_train = pd.read_csv(filename, encoding=\"SHIFT_JIS\", header=0, nrows=None)\n",
    "\n",
    "        targets = []\n",
    "        name_ids = []\n",
    "        localities = []\n",
    "\n",
    "        for index, row in df_train.iterrows():\n",
    "\n",
    "            # 結果をホットベクトル化\n",
    "            result = row['result']\n",
    "            if result == 1:\n",
    "                target = 1\n",
    "            else:\n",
    "                target = 0\n",
    "            targets.append(target)    \n",
    "\n",
    "            # 名前をハッシュを使ってID化\n",
    "            name = row['name']\n",
    "            name_hash = hashlib.md5(name.encode()).hexdigest()\n",
    "            name_id = name_hash[-8:]\n",
    "            name_ids.append(name_id)\n",
    "\n",
    "            # 　ランクの例外処理\n",
    "            if row['rank'] == 'SS':\n",
    "                df_train.loc[index, 'rank'] = '0'\n",
    "            elif row['rank'] == 'L1':\n",
    "                df_train.loc[index, 'rank'] = '6'\n",
    "\n",
    "            # 出身地を地区毎にグループ化\n",
    "            prefecture = row['prefecture']\n",
    "            if prefecture in {'1', '2', '3', '5'}:\n",
    "                locality = '1' #北東北\n",
    "            elif prefecture in {'4', '6', '7'}:\n",
    "                locality = '2' #南東北\n",
    "            elif prefecture in {'8', '9'}:\n",
    "                locality = '3' #茨栃\n",
    "            elif prefecture in {'11', '13'}:\n",
    "                locality = '4' #埼京\n",
    "            elif prefecture in {'10', '15', '19', '20'}:\n",
    "                locality = '5' #上信越\n",
    "            elif prefecture in {'12', '14', '22'}:\n",
    "                locality = '6' #南関東\n",
    "            elif prefecture in {'16', '17', '21', '23', '24'}:\n",
    "                locality = '7' #中部\n",
    "            elif prefecture in {'18', '25', '26', '27', '28', '29', '30'}:\n",
    "                locality = '8' #近畿\n",
    "            elif prefecture in {'31', '32', '33', '34', '35'}:\n",
    "                locality = '9' #中国\n",
    "            elif prefecture in {'36', '37', '38', '39'}:\n",
    "                locality = '10' #四国\n",
    "            elif prefecture in {'40', '41', '42', '43', '44', '45', '46', '47'}:\n",
    "                locality = '11' #九州\n",
    "            else:\n",
    "                locality = '12' #外国\n",
    "\n",
    "            localities.append(locality)\n",
    "\n",
    "        # 前処理したデータのデータフレームへの置き換え\n",
    "        df_train['target'] = targets\n",
    "        df_train['name_id'] = name_ids\n",
    "        df_train['locality'] = localities\n",
    "\n",
    "        # カラムの順番入れ替え（見やすさのため）\n",
    "        columns = list(df_train.columns)\n",
    "        columns.remove('name_id')\n",
    "        columns.insert(columns.index(\"name\") + 1, \"name_id\")\n",
    "        columns.remove('locality')\n",
    "        columns.insert(columns.index(\"prefecture\") + 1, \"locality\")\n",
    "\n",
    "        df_train = df_train.loc[:,columns]\n",
    "        \n",
    "        if init_flag:\n",
    "            df_train_concat = df_train\n",
    "            init_flag = False\n",
    "        else:\n",
    "            df_train_concat = pd.concat([df_train_concat, df_train])\n",
    "    \n",
    "    return df_train_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(df_train):\n",
    "    X = []\n",
    "    target = []\n",
    "        \n",
    "    # 各レース毎に\n",
    "    grouped = df_train.groupby(['date', 'place', 'race_num'])\n",
    "    for race_name, group in tqdm(grouped):\n",
    "        #print(race_name)\n",
    "        racer_count = group.shape[0]\n",
    "        # もし、９輪ではないレースは、トレーニングの対象から外す（モデルを固めるため）\n",
    "        if racer_count != 9:\n",
    "            continue\n",
    "        X.append(group[X_columns].values)\n",
    "        target.append(group['target'].values)\n",
    "\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n",
    "    d_ = np.array(target)\n",
    "\n",
    "    X_train, X_test, d_train, d_test = train_test_split(X, d_, test_size = 0.2)\n",
    "\n",
    "    return X_train, X_test, d_train, d_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aomori', 'chiba', 'hakodate', 'hiratsuka', 'ito', 'iwakitaira', 'kawasaki', 'keiokaku', 'maebashi', 'matsudo', 'odawara', 'omiya', 'seibuen', 'shizuoka', 'tachikawa', 'toride', 'utsunomiya', 'yahiko']\n"
     ]
    }
   ],
   "source": [
    "places = []\n",
    "for filename in os.listdir('data/'):\n",
    "    place = filename.split('_')[0]\n",
    "    places.append(place)\n",
    "print(places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Data...\n",
      "loading data for kawasaki\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ttsuchiy\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2901: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data for hiratsuka\n"
     ]
    }
   ],
   "source": [
    "places = ['kawasaki', 'hiratsuka']\n",
    "\n",
    "print(\"Loading Training Data...\")\n",
    "df_train = get_df_train(places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(object):\n",
    "    def __init__(self, n_in, n_hiddens, n_out):\n",
    "        self.n_in = n_in\n",
    "        self.n_hiddens = n_hiddens\n",
    "        self.n_out = n_out\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        self._x = None\n",
    "        self._y = None\n",
    "        self._t = None,\n",
    "        self._keep_prob = None\n",
    "        self._sess = None\n",
    "        self._history = {\n",
    "            'accuracy': [],\n",
    "            'loss': []\n",
    "        }\n",
    "\n",
    "    def weight_variable(self, shape):\n",
    "        # He 初期化\n",
    "        n_sum = 1\n",
    "        for n in shape:\n",
    "            n_sum *= n\n",
    "        stddev = math.sqrt(2.0 / n_sum)\n",
    "        print('stddev: ', stddev)\n",
    "        initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def bias_variable(self, shape):\n",
    "        initial = tf.zeros(shape)\n",
    "        return tf.Variable(initial)\n",
    "\n",
    "    def inference(self, x, keep_prob):\n",
    "        # 入力層 - 隠れ層、隠れ層 - 隠れ層\n",
    "        for i, n_hidden in enumerate(self.n_hiddens):\n",
    "            if i == 0:\n",
    "                input = x\n",
    "                input_dim = self.n_in\n",
    "            else:\n",
    "                input = output\n",
    "                input_dim = self.n_hiddens[i-1]\n",
    "\n",
    "            self.weights.append(self.weight_variable([input_dim, n_hidden]))\n",
    "            self.biases.append(self.bias_variable([n_hidden]))\n",
    "\n",
    "            h = tf.nn.relu(tf.matmul(input, self.weights[-1]) + self.biases[-1])\n",
    "            output = tf.nn.dropout(h, keep_prob)\n",
    "\n",
    "        # 隠れ層 - 出力層\n",
    "        self.weights.append(self.weight_variable([self.n_hiddens[-1], self.n_out]))\n",
    "        self.biases.append(self.bias_variable([self.n_out]))\n",
    "\n",
    "        y = tf.nn.softmax(tf.matmul(output, self.weights[-1]) + self.biases[-1])\n",
    "        \n",
    "        return y\n",
    "\n",
    "    def loss(self, y, t):\n",
    "        # クロスエントロピー\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(t * tf.log(y), axis=1))\n",
    "        # L2 正則化\n",
    "        l2_decay = 0.0001\n",
    "        l2_losses = [tf.nn.l2_loss(w) for w in self.weights]\n",
    "        l2_loss = l2_decay * tf.add_n(l2_losses)\n",
    "        loss = cross_entropy + l2_loss\n",
    "        return loss\n",
    "\n",
    "    def training(self, loss):\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        train_step = optimizer.minimize(loss)\n",
    "        return train_step\n",
    "\n",
    "    def accuracy(self, y, t):\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(t, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        return accuracy\n",
    "\n",
    "    def fit(self, X_train, Y_train, nb_epoch=100, batch_size=100, p_keep=0.5, verbose=1):\n",
    "        x = tf.placeholder(tf.float32, shape=[None, self.n_in])\n",
    "        t = tf.placeholder(tf.float32, shape=[None, self.n_out])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        self._x = x\n",
    "        self._t = t\n",
    "        self._keep_prob = keep_prob\n",
    "\n",
    "        y = self.inference(x, keep_prob)\n",
    "        loss = self.loss(y, t)\n",
    "        train_step = self.training(loss)\n",
    "        accuracy = self.accuracy(y, t)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "\n",
    "        self._y = y\n",
    "        self._sess = sess\n",
    "\n",
    "        N_train = len(X_train)\n",
    "        n_batches = N_train // batch_size\n",
    "\n",
    "        for epoch in range(nb_epoch):\n",
    "            X_, Y_ = shuffle(X_train, Y_train)\n",
    "\n",
    "            for i in range(n_batches):\n",
    "                start = i * batch_size\n",
    "                end = start + batch_size\n",
    "\n",
    "                sess.run(train_step, feed_dict={\n",
    "                    x: X_[start:end],\n",
    "                    t: Y_[start:end],\n",
    "                    keep_prob: p_keep\n",
    "                })\n",
    "            loss_ = loss.eval(session=sess, feed_dict={\n",
    "                x: X_train,\n",
    "                t: Y_train,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "            accuracy_ = accuracy.eval(session=sess, feed_dict={\n",
    "                x: X_train,\n",
    "                t: Y_train,\n",
    "                keep_prob: 1.0\n",
    "            })\n",
    "            self._history['loss'].append(loss_)\n",
    "            self._history['accuracy'].append(accuracy_)\n",
    "\n",
    "            if verbose:\n",
    "                print('epoch:', epoch,\n",
    "                      ' loss:', loss_,\n",
    "                      ' accuracy:', accuracy_)\n",
    "\n",
    "        return self._history\n",
    "\n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        accuracy = self.accuracy(self._y, self._t)\n",
    "        return accuracy.eval(session=self._sess, feed_dict={\n",
    "            self._x: X_test,\n",
    "            self._t: Y_test,\n",
    "            self._keep_prob: 1.0\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Training/Test Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 7370/7370 [00:07<00:00, 950.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stddev:  0.004910463758239913\n",
      "stddev:  0.020833333333333332\n",
      "epoch: 0  loss: 1.9588829  accuracy: 0.27259186\n",
      "epoch: 1  loss: 1.9504446  accuracy: 0.30933467\n",
      "epoch: 2  loss: 1.9193548  accuracy: 0.28326714\n",
      "epoch: 3  loss: 1.9044218  accuracy: 0.30958292\n",
      "epoch: 4  loss: 1.8976045  accuracy: 0.31305858\n",
      "epoch: 5  loss: 1.8978404  accuracy: 0.32919562\n",
      "epoch: 6  loss: 1.9098091  accuracy: 0.32174778\n",
      "epoch: 7  loss: 1.9041033  accuracy: 0.32497516\n",
      "epoch: 8  loss: 1.9111382  accuracy: 0.31653425\n",
      "epoch: 9  loss: 1.8796667  accuracy: 0.32571995\n",
      "epoch: 10  loss: 1.9242587  accuracy: 0.30561072\n",
      "epoch: 11  loss: 1.888956  accuracy: 0.33440915\n",
      "epoch: 12  loss: 1.9093066  accuracy: 0.30734855\n",
      "epoch: 13  loss: 1.8927796  accuracy: 0.32423037\n",
      "epoch: 14  loss: 1.8899994  accuracy: 0.32199603\n",
      "epoch: 15  loss: 1.8974435  accuracy: 0.30958292\n",
      "epoch: 16  loss: 1.8662931  accuracy: 0.3306852\n",
      "epoch: 17  loss: 1.8753008  accuracy: 0.31603774\n",
      "epoch: 18  loss: 1.912779  accuracy: 0.316286\n",
      "epoch: 19  loss: 1.870875  accuracy: 0.33714002\n",
      "epoch: 20  loss: 1.8613969  accuracy: 0.321003\n",
      "epoch: 21  loss: 1.8619215  accuracy: 0.3214995\n",
      "epoch: 22  loss: 1.865849  accuracy: 0.31578946\n",
      "epoch: 23  loss: 1.8475777  accuracy: 0.33440915\n",
      "epoch: 24  loss: 1.8463744  accuracy: 0.3214995\n",
      "epoch: 25  loss: 1.8524736  accuracy: 0.33887786\n",
      "epoch: 26  loss: 1.8504205  accuracy: 0.33316782\n",
      "epoch: 27  loss: 1.8653123  accuracy: 0.3262165\n",
      "epoch: 28  loss: 1.8533438  accuracy: 0.33242303\n",
      "epoch: 29  loss: 1.8355254  accuracy: 0.33416086\n",
      "epoch: 30  loss: 1.8301624  accuracy: 0.34558094\n",
      "epoch: 31  loss: 1.8278959  accuracy: 0.3406157\n",
      "epoch: 32  loss: 1.844095  accuracy: 0.3354022\n",
      "epoch: 33  loss: 1.8351599  accuracy: 0.33217478\n",
      "epoch: 34  loss: 1.8607711  accuracy: 0.2979146\n",
      "epoch: 35  loss: 1.8333882  accuracy: 0.34657398\n",
      "epoch: 36  loss: 1.8525026  accuracy: 0.34210527\n",
      "epoch: 37  loss: 1.8351307  accuracy: 0.33093345\n",
      "epoch: 38  loss: 1.8560308  accuracy: 0.33043694\n",
      "epoch: 39  loss: 1.8502747  accuracy: 0.33813307\n",
      "epoch: 40  loss: 1.8437495  accuracy: 0.33962265\n",
      "epoch: 41  loss: 1.8601952  accuracy: 0.33639523\n",
      "epoch: 42  loss: 1.8422965  accuracy: 0.32795432\n",
      "epoch: 43  loss: 1.8175025  accuracy: 0.3445879\n",
      "epoch: 44  loss: 1.8238347  accuracy: 0.34657398\n",
      "epoch: 45  loss: 1.8411555  accuracy: 0.33738828\n",
      "epoch: 46  loss: 1.8294797  accuracy: 0.33416086\n",
      "epoch: 47  loss: 1.8217617  accuracy: 0.33689177\n",
      "epoch: 48  loss: 1.8042264  accuracy: 0.34359485\n",
      "epoch: 49  loss: 1.84173  accuracy: 0.33838132\n",
      "epoch: 50  loss: 1.8201679  accuracy: 0.34285006\n",
      "epoch: 51  loss: 1.8192149  accuracy: 0.33565044\n",
      "epoch: 52  loss: 1.8206736  accuracy: 0.3498014\n",
      "epoch: 53  loss: 1.8129394  accuracy: 0.35054618\n",
      "epoch: 54  loss: 1.8433208  accuracy: 0.34086394\n",
      "epoch: 55  loss: 1.838022  accuracy: 0.34533268\n",
      "epoch: 56  loss: 1.8085713  accuracy: 0.34707052\n",
      "epoch: 57  loss: 1.8326844  accuracy: 0.352284\n",
      "epoch: 58  loss: 1.8170553  accuracy: 0.3346574\n",
      "epoch: 59  loss: 1.8188113  accuracy: 0.3445879\n",
      "epoch: 60  loss: 1.8025427  accuracy: 0.35278055\n",
      "epoch: 61  loss: 1.8022125  accuracy: 0.352284\n",
      "epoch: 62  loss: 1.8372147  accuracy: 0.3438431\n",
      "epoch: 63  loss: 1.8004465  accuracy: 0.3498014\n",
      "epoch: 64  loss: 1.8081112  accuracy: 0.33341607\n",
      "epoch: 65  loss: 1.8219024  accuracy: 0.33565044\n",
      "epoch: 66  loss: 1.815673  accuracy: 0.3478153\n",
      "epoch: 67  loss: 1.811611  accuracy: 0.3391261\n",
      "epoch: 68  loss: 1.7847991  accuracy: 0.35799405\n",
      "epoch: 69  loss: 1.7899795  accuracy: 0.35054618\n",
      "epoch: 70  loss: 1.7803963  accuracy: 0.35451838\n",
      "epoch: 71  loss: 1.7953022  accuracy: 0.3642006\n",
      "epoch: 72  loss: 1.7856776  accuracy: 0.35402185\n",
      "epoch: 73  loss: 1.8037682  accuracy: 0.3386296\n",
      "epoch: 74  loss: 1.8193194  accuracy: 0.35526314\n",
      "epoch: 75  loss: 1.7672579  accuracy: 0.35278055\n",
      "epoch: 76  loss: 1.7866925  accuracy: 0.36494538\n",
      "epoch: 77  loss: 1.7866739  accuracy: 0.3574975\n",
      "epoch: 78  loss: 1.7931135  accuracy: 0.3550149\n",
      "epoch: 79  loss: 1.8064128  accuracy: 0.352284\n",
      "epoch: 80  loss: 1.8080964  accuracy: 0.35327706\n",
      "epoch: 81  loss: 1.7872043  accuracy: 0.35402185\n",
      "epoch: 82  loss: 1.8056705  accuracy: 0.34334657\n",
      "epoch: 83  loss: 1.7847484  accuracy: 0.34483615\n",
      "epoch: 84  loss: 1.8420643  accuracy: 0.33291957\n",
      "epoch: 85  loss: 1.7900671  accuracy: 0.35178748\n",
      "epoch: 86  loss: 1.8025569  accuracy: 0.3490566\n",
      "epoch: 87  loss: 1.8144777  accuracy: 0.35253227\n",
      "epoch: 88  loss: 1.7690542  accuracy: 0.35650447\n",
      "epoch: 89  loss: 1.8166282  accuracy: 0.35402185\n",
      "epoch: 90  loss: 1.7851901  accuracy: 0.33763653\n",
      "epoch: 91  loss: 1.7687472  accuracy: 0.35476664\n",
      "epoch: 92  loss: 1.7839172  accuracy: 0.33813307\n",
      "epoch: 93  loss: 1.7906649  accuracy: 0.3478153\n",
      "epoch: 94  loss: 1.7810023  accuracy: 0.36196622\n",
      "epoch: 95  loss: 1.7460868  accuracy: 0.36395234\n",
      "epoch: 96  loss: 1.7562177  accuracy: 0.367428\n",
      "epoch: 97  loss: 1.7859517  accuracy: 0.35774577\n",
      "epoch: 98  loss: 1.7866596  accuracy: 0.35402185\n",
      "epoch: 99  loss: 1.76909  accuracy: 0.3535253\n",
      "epoch: 100  loss: 1.7610537  accuracy: 0.36122146\n",
      "epoch: 101  loss: 1.7781665  accuracy: 0.3582423\n",
      "epoch: 102  loss: 1.777695  accuracy: 0.35799405\n",
      "epoch: 103  loss: 1.797933  accuracy: 0.34955314\n",
      "epoch: 104  loss: 1.7993863  accuracy: 0.35774577\n",
      "epoch: 105  loss: 1.778317  accuracy: 0.35004964\n",
      "epoch: 106  loss: 1.780478  accuracy: 0.35575968\n",
      "epoch: 107  loss: 1.759236  accuracy: 0.3535253\n",
      "epoch: 108  loss: 1.7807922  accuracy: 0.36246276\n",
      "epoch: 109  loss: 1.745756  accuracy: 0.37313804\n",
      "epoch: 110  loss: 1.7860816  accuracy: 0.35849056\n",
      "epoch: 111  loss: 1.7808384  accuracy: 0.3582423\n",
      "epoch: 112  loss: 1.7474082  accuracy: 0.36767626\n",
      "epoch: 113  loss: 1.771924  accuracy: 0.34756702\n",
      "epoch: 114  loss: 1.7615452  accuracy: 0.36444885\n",
      "epoch: 115  loss: 1.7934151  accuracy: 0.35724926\n",
      "epoch: 116  loss: 1.7532959  accuracy: 0.3642006\n",
      "epoch: 117  loss: 1.7782322  accuracy: 0.3637041\n",
      "epoch: 118  loss: 1.7709256  accuracy: 0.35600793\n",
      "epoch: 119  loss: 1.7567301  accuracy: 0.3589871\n",
      "epoch: 120  loss: 1.7763678  accuracy: 0.34558094\n",
      "epoch: 121  loss: 1.7644002  accuracy: 0.3589871\n",
      "epoch: 122  loss: 1.7191391  accuracy: 0.3726415\n",
      "epoch: 123  loss: 1.7572966  accuracy: 0.36395234\n",
      "epoch: 124  loss: 1.7588799  accuracy: 0.37015888\n",
      "epoch: 125  loss: 1.7434899  accuracy: 0.36643496\n",
      "epoch: 126  loss: 1.7693304  accuracy: 0.3478153\n",
      "epoch: 127  loss: 1.7659603  accuracy: 0.3542701\n",
      "epoch: 128  loss: 1.7328094  accuracy: 0.36395234\n",
      "epoch: 129  loss: 1.757439  accuracy: 0.37065542\n",
      "epoch: 130  loss: 1.7845082  accuracy: 0.3445879\n",
      "epoch: 131  loss: 1.7693971  accuracy: 0.36891758\n",
      "epoch: 132  loss: 1.7455301  accuracy: 0.3642006\n",
      "epoch: 133  loss: 1.7362827  accuracy: 0.37711024\n",
      "epoch: 134  loss: 1.741305  accuracy: 0.37363455\n",
      "epoch: 135  loss: 1.7566133  accuracy: 0.36891758\n",
      "epoch: 136  loss: 1.7180853  accuracy: 0.37363455\n",
      "epoch: 137  loss: 1.7660937  accuracy: 0.36643496\n",
      "epoch: 138  loss: 1.7475451  accuracy: 0.38455808\n",
      "epoch: 139  loss: 1.7394698  accuracy: 0.3574975\n",
      "epoch: 140  loss: 1.7133695  accuracy: 0.37462762\n",
      "epoch: 141  loss: 1.758433  accuracy: 0.35675272\n",
      "epoch: 142  loss: 1.7250185  accuracy: 0.37239325\n",
      "epoch: 143  loss: 1.7582754  accuracy: 0.37288976\n",
      "epoch: 144  loss: 1.734677  accuracy: 0.37636545\n",
      "epoch: 145  loss: 1.7127708  accuracy: 0.37835154\n",
      "epoch: 146  loss: 1.7317914  accuracy: 0.357001\n",
      "epoch: 147  loss: 1.7195481  accuracy: 0.37413108\n",
      "epoch: 148  loss: 1.7347267  accuracy: 0.37239325\n",
      "epoch: 149  loss: 1.736569  accuracy: 0.372145\n",
      "epoch: 150  loss: 1.7438991  accuracy: 0.37363455\n",
      "epoch: 151  loss: 1.7266603  accuracy: 0.36668321\n",
      "epoch: 152  loss: 1.7196285  accuracy: 0.36544192\n",
      "epoch: 153  loss: 1.7285053  accuracy: 0.36916584\n",
      "epoch: 154  loss: 1.7276543  accuracy: 0.37537238\n",
      "epoch: 155  loss: 1.7194632  accuracy: 0.37462762\n",
      "epoch: 156  loss: 1.7573501  accuracy: 0.36519364\n",
      "epoch: 157  loss: 1.6976155  accuracy: 0.37363455\n",
      "epoch: 158  loss: 1.7502242  accuracy: 0.3686693\n",
      "epoch: 159  loss: 1.6977929  accuracy: 0.37288976\n",
      "epoch: 160  loss: 1.7590368  accuracy: 0.3642006\n",
      "epoch: 161  loss: 1.6994098  accuracy: 0.38108242\n",
      "epoch: 162  loss: 1.7107464  accuracy: 0.38157895\n",
      "epoch: 163  loss: 1.7471464  accuracy: 0.35575968\n",
      "epoch: 164  loss: 1.7595071  accuracy: 0.35526314\n",
      "epoch: 165  loss: 1.7344772  accuracy: 0.36966237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 166  loss: 1.694603  accuracy: 0.37562066\n",
      "epoch: 167  loss: 1.7217163  accuracy: 0.36916584\n",
      "epoch: 168  loss: 1.7162269  accuracy: 0.37462762\n",
      "epoch: 169  loss: 1.7018117  accuracy: 0.37313804\n",
      "epoch: 170  loss: 1.723131  accuracy: 0.3785998\n",
      "epoch: 171  loss: 1.716079  accuracy: 0.3785998\n",
      "epoch: 172  loss: 1.7230312  accuracy: 0.377855\n",
      "epoch: 173  loss: 1.7112857  accuracy: 0.37884808\n",
      "epoch: 174  loss: 1.7209193  accuracy: 0.38480636\n",
      "epoch: 175  loss: 1.752122  accuracy: 0.36171797\n",
      "epoch: 176  loss: 1.7374487  accuracy: 0.37537238\n",
      "epoch: 177  loss: 1.7113328  accuracy: 0.37437934\n",
      "epoch: 178  loss: 1.7160957  accuracy: 0.38455808\n",
      "epoch: 179  loss: 1.7438133  accuracy: 0.35476664\n",
      "epoch: 180  loss: 1.7350156  accuracy: 0.36146972\n",
      "epoch: 181  loss: 1.7401284  accuracy: 0.37164846\n",
      "epoch: 182  loss: 1.7169421  accuracy: 0.36544192\n",
      "epoch: 183  loss: 1.6843542  accuracy: 0.38207546\n",
      "epoch: 184  loss: 1.7394558  accuracy: 0.37413108\n",
      "epoch: 185  loss: 1.698438  accuracy: 0.38530287\n",
      "epoch: 186  loss: 1.7222537  accuracy: 0.38356504\n",
      "epoch: 187  loss: 1.7153108  accuracy: 0.362711\n",
      "epoch: 188  loss: 1.7270267  accuracy: 0.367428\n",
      "epoch: 189  loss: 1.7448641  accuracy: 0.3714002\n",
      "epoch: 190  loss: 1.7016414  accuracy: 0.37934458\n",
      "epoch: 191  loss: 1.6997232  accuracy: 0.38555115\n",
      "epoch: 192  loss: 1.7012511  accuracy: 0.37363455\n",
      "epoch: 193  loss: 1.7072301  accuracy: 0.3813307\n",
      "epoch: 194  loss: 1.6980712  accuracy: 0.37586892\n",
      "epoch: 195  loss: 1.7065609  accuracy: 0.3766137\n",
      "epoch: 196  loss: 1.7200005  accuracy: 0.377855\n",
      "epoch: 197  loss: 1.7139298  accuracy: 0.3733863\n",
      "epoch: 198  loss: 1.6828855  accuracy: 0.3818272\n",
      "epoch: 199  loss: 1.6929373  accuracy: 0.37487587\n",
      "epoch: 200  loss: 1.672097  accuracy: 0.38530287\n",
      "epoch: 201  loss: 1.7061821  accuracy: 0.38753724\n",
      "epoch: 202  loss: 1.6764662  accuracy: 0.38902682\n",
      "epoch: 203  loss: 1.6878998  accuracy: 0.3818272\n",
      "epoch: 204  loss: 1.6760926  accuracy: 0.3818272\n",
      "epoch: 205  loss: 1.6785387  accuracy: 0.37909633\n",
      "epoch: 206  loss: 1.7604904  accuracy: 0.36097318\n",
      "epoch: 207  loss: 1.702491  accuracy: 0.3862959\n",
      "epoch: 208  loss: 1.6895211  accuracy: 0.3714002\n",
      "epoch: 209  loss: 1.722037  accuracy: 0.36072493\n",
      "epoch: 210  loss: 1.6983379  accuracy: 0.38306853\n",
      "epoch: 211  loss: 1.707011  accuracy: 0.38679245\n",
      "epoch: 212  loss: 1.7243422  accuracy: 0.37835154\n",
      "epoch: 213  loss: 1.6996325  accuracy: 0.38430983\n",
      "epoch: 214  loss: 1.7200831  accuracy: 0.38033763\n",
      "epoch: 215  loss: 1.721994  accuracy: 0.37388283\n",
      "epoch: 216  loss: 1.7054577  accuracy: 0.37487587\n",
      "epoch: 217  loss: 1.6910037  accuracy: 0.38282025\n",
      "epoch: 218  loss: 1.7055571  accuracy: 0.38108242\n",
      "epoch: 219  loss: 1.6781342  accuracy: 0.38505462\n",
      "epoch: 220  loss: 1.6724166  accuracy: 0.3962264\n",
      "epoch: 221  loss: 1.6628997  accuracy: 0.39324728\n",
      "epoch: 222  loss: 1.7315775  accuracy: 0.38331679\n",
      "epoch: 223  loss: 1.6573325  accuracy: 0.39523336\n",
      "epoch: 224  loss: 1.6824025  accuracy: 0.38555115\n",
      "epoch: 225  loss: 1.7086456  accuracy: 0.37686196\n",
      "epoch: 226  loss: 1.6890684  accuracy: 0.3865442\n",
      "epoch: 227  loss: 1.6995301  accuracy: 0.367428\n",
      "epoch: 228  loss: 1.69269  accuracy: 0.3694141\n",
      "epoch: 229  loss: 1.6889699  accuracy: 0.38952333\n",
      "epoch: 230  loss: 1.7189771  accuracy: 0.372145\n",
      "epoch: 231  loss: 1.6685027  accuracy: 0.38902682\n",
      "epoch: 232  loss: 1.7287809  accuracy: 0.38157895\n",
      "epoch: 233  loss: 1.6430849  accuracy: 0.3949851\n",
      "epoch: 234  loss: 1.65612  accuracy: 0.39026812\n",
      "epoch: 235  loss: 1.6764473  accuracy: 0.38505462\n",
      "epoch: 236  loss: 1.697939  accuracy: 0.37313804\n",
      "epoch: 237  loss: 1.7292129  accuracy: 0.3718967\n",
      "epoch: 238  loss: 1.6984075  accuracy: 0.3917577\n",
      "epoch: 239  loss: 1.7233164  accuracy: 0.35551143\n",
      "epoch: 240  loss: 1.6574899  accuracy: 0.39523336\n",
      "epoch: 241  loss: 1.6576827  accuracy: 0.3925025\n",
      "epoch: 242  loss: 1.6879426  accuracy: 0.38331679\n",
      "epoch: 243  loss: 1.6856278  accuracy: 0.39126116\n",
      "epoch: 244  loss: 1.6659528  accuracy: 0.39051637\n",
      "epoch: 245  loss: 1.6778923  accuracy: 0.3877855\n",
      "epoch: 246  loss: 1.6929774  accuracy: 0.3726415\n",
      "epoch: 247  loss: 1.6928066  accuracy: 0.36767626\n",
      "epoch: 248  loss: 1.6990564  accuracy: 0.3681728\n",
      "epoch: 249  loss: 1.650906  accuracy: 0.40292948\n",
      "epoch: 250  loss: 1.6816719  accuracy: 0.38083416\n",
      "epoch: 251  loss: 1.6521949  accuracy: 0.382572\n",
      "epoch: 252  loss: 1.7118216  accuracy: 0.3781033\n",
      "epoch: 253  loss: 1.6546531  accuracy: 0.39324728\n",
      "epoch: 254  loss: 1.6666031  accuracy: 0.37959284\n",
      "epoch: 255  loss: 1.6529802  accuracy: 0.40640515\n",
      "epoch: 256  loss: 1.693067  accuracy: 0.38877854\n",
      "epoch: 257  loss: 1.7131841  accuracy: 0.37288976\n",
      "epoch: 258  loss: 1.684132  accuracy: 0.37512413\n",
      "epoch: 259  loss: 1.6569893  accuracy: 0.3964747\n",
      "epoch: 260  loss: 1.7030139  accuracy: 0.36916584\n",
      "epoch: 261  loss: 1.6767801  accuracy: 0.392999\n",
      "epoch: 262  loss: 1.6843517  accuracy: 0.38803378\n",
      "epoch: 263  loss: 1.6541008  accuracy: 0.39200595\n",
      "epoch: 264  loss: 1.6698543  accuracy: 0.3962264\n",
      "epoch: 265  loss: 1.7163771  accuracy: 0.3813307\n",
      "epoch: 266  loss: 1.6779583  accuracy: 0.38232374\n",
      "epoch: 267  loss: 1.6917176  accuracy: 0.3917577\n",
      "epoch: 268  loss: 1.69892  accuracy: 0.38877854\n",
      "epoch: 269  loss: 1.7142452  accuracy: 0.38430983\n",
      "epoch: 270  loss: 1.6676704  accuracy: 0.39225423\n",
      "epoch: 271  loss: 1.7108982  accuracy: 0.39424032\n",
      "epoch: 272  loss: 1.7138889  accuracy: 0.38008937\n",
      "epoch: 273  loss: 1.7326003  accuracy: 0.3781033\n",
      "epoch: 274  loss: 1.6621617  accuracy: 0.39126116\n",
      "epoch: 275  loss: 1.7045321  accuracy: 0.36693147\n",
      "epoch: 276  loss: 1.6883899  accuracy: 0.37586892\n",
      "epoch: 277  loss: 1.7084379  accuracy: 0.3686693\n",
      "epoch: 278  loss: 1.6636406  accuracy: 0.39796424\n",
      "epoch: 279  loss: 1.6664109  accuracy: 0.40441906\n",
      "epoch: 280  loss: 1.6739134  accuracy: 0.3925025\n",
      "epoch: 281  loss: 1.6517698  accuracy: 0.4054121\n",
      "epoch: 282  loss: 1.6768972  accuracy: 0.39324728\n",
      "epoch: 283  loss: 1.6580396  accuracy: 0.39920557\n",
      "epoch: 284  loss: 1.6693692  accuracy: 0.39225423\n",
      "epoch: 285  loss: 1.6615815  accuracy: 0.3969712\n",
      "epoch: 286  loss: 1.6977552  accuracy: 0.38853028\n",
      "epoch: 287  loss: 1.7019839  accuracy: 0.36519364\n",
      "epoch: 288  loss: 1.6884453  accuracy: 0.38530287\n",
      "epoch: 289  loss: 1.6638352  accuracy: 0.38927507\n",
      "epoch: 290  loss: 1.6280663  accuracy: 0.39597815\n",
      "epoch: 291  loss: 1.6210812  accuracy: 0.41583914\n",
      "epoch: 292  loss: 1.7117801  accuracy: 0.36966237\n",
      "epoch: 293  loss: 1.6717281  accuracy: 0.39076465\n",
      "epoch: 294  loss: 1.6519496  accuracy: 0.38679245\n",
      "epoch: 295  loss: 1.6233995  accuracy: 0.40863952\n",
      "epoch: 296  loss: 1.6429266  accuracy: 0.39349553\n",
      "epoch: 297  loss: 1.6557106  accuracy: 0.40069515\n",
      "epoch: 298  loss: 1.6774305  accuracy: 0.39001986\n",
      "epoch: 299  loss: 1.6835655  accuracy: 0.3857994\n",
      "accuracy:  0.2591857\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating Training/Test Data\")\n",
    "X_train, X_test, Y_train, Y_test = get_train_test_data(df_train)\n",
    "\n",
    "\n",
    "model = DNN(n_in = len(X_train[1]), n_hiddens=[512], n_out=9)\n",
    "\n",
    "history = model.fit(X_train, Y_train, nb_epoch = 300, batch_size=32, p_keep=0.5)\n",
    "\n",
    "accuracy = model.evaluate(X_test, Y_test)\n",
    "print('accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()  # 2つのプロットを関連付ける\n",
    "\n",
    "ax1.plot(history['loss'], label='loss', color='orange')\n",
    "ax1.set_ylabel('loss')\n",
    "ax1.set_ylim(0, 2.5)\n",
    "ax1.legend(loc='best', bbox_to_anchor=(1.01, 0.71, 0.322, .100), borderaxespad=0.,)\n",
    "\n",
    "ax2.plot(history['accuracy'], label='accuracy', color='dodgerblue')\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.set_ylim(0, 1.0)\n",
    "ax2.legend(loc='best', bbox_to_anchor=(1.01, 0.8, 0.4, .100), borderaxespad=0.,)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
