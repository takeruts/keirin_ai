{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timedelta, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_url(target_month, place):\n",
    "    year = target_month.strftime(\"%Y\")\n",
    "    month = target_month.strftime(\"%m\")\n",
    "    base = 'https://keirin.kdreams.jp'\n",
    "    baseAdd1 = \"/\" + place + \"/schedule/\" + year + \"/\" + month\n",
    "    url = base + baseAdd1\n",
    "    return urllib.parse.quote_plus(url, \"/:?=&\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_racedetail_to_csv(racedetail_links, kaisaidate, place, filename):\n",
    "\n",
    "    for i, racedetail_link in enumerate(racedetail_links):\n",
    "\n",
    "        race_num = str(i + 1)\n",
    "        \n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        time.sleep(sleep_time)\n",
    "        try:\n",
    "            response = requests.get(racedetail_link, headers=headers)\n",
    "        except:\n",
    "            print(\"Response error:\", racedetail_link)\n",
    "            continue\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        print(\"RACE RESULT\", kaisaidate, place, race_num)\n",
    "\n",
    "        result_bs = soup.find(\"table\", class_=\"result_table\")\n",
    "        if not result_bs:\n",
    "            continue\n",
    "        trs = result_bs.find_all(\"tr\")\n",
    "        trs.pop(0)\n",
    "        \n",
    "        race_result = []\n",
    "        for tr in trs:\n",
    "            result_rows = []\n",
    "            tds = tr.find_all(\"td\")\n",
    "            for td in tds:\n",
    "                result_rows.append(td.text)\n",
    "            #print(result_rows)\n",
    "            # make list to store result by order\n",
    "            race_result.append(result_rows[2])\n",
    "\n",
    "        print(race_result)\n",
    "\n",
    "        print(\"RACE RECORD\")\n",
    "        racecard_bs = soup.find(\"table\", class_=\"racecard_table\")\n",
    "        #print(racecard)\n",
    "        if not racecard_bs:\n",
    "            continue\n",
    "        riders_bs = racecard_bs.find_all(\"tr\", class_=re.compile(\"^n\"))\n",
    "            \n",
    "        for rider_bs in riders_bs:\n",
    "            rows = []\n",
    "            for td in rider_bs.find_all(\"td\"):\n",
    "                row = td.text\n",
    "                row = ''.join(row.split())\n",
    "                rows.append(row)\n",
    "            if len(rows) < 23:\n",
    "                rows.insert(3, bracket)\n",
    "\n",
    "            names = rider_bs.find(\"td\", class_=\"rider bdr_r\").get_text().strip().splitlines()\n",
    "            name = names[0]\n",
    "            homes = ''.join(names[1].split()).split(\"/\")\n",
    "            prefecture = homes[0]\n",
    "            age = homes[1]\n",
    "            period = homes[2]\n",
    "\n",
    "            rows.pop(5)\n",
    "            rows.insert(5, name)\n",
    "            rows.insert(6, prefecture)\n",
    "            rows.insert(7, age)\n",
    "            rows.insert(8, period)\n",
    "\n",
    "            #print(rows)\n",
    "\n",
    "            rows[0] = rows[0].replace('◎', '9').replace('○', '8').replace('△', '7').replace('▲', '6').replace('×', '5').replace('注', '4')\n",
    "            bracket = rows[3]\n",
    "            rows[6] = rows[6].replace('北海道', '1').replace('青森', '2').replace('岩手', '3').replace('宮城', '4').replace('秋田', '5').replace('山形', '6').replace('福島', '7').replace('茨城', '8').replace('栃木', '9').replace('群馬', '10').replace('埼玉', '11').replace('千葉', '12').replace('東京', '13').replace('神奈川', '14').replace('新潟', '15').replace('富山', '16').replace('石川', '17').replace('福井', '18').replace('山梨', '19').replace('長野', '20').replace('岐阜', '21').replace('静岡', '22').replace('愛知', '23').replace('三重', '24').replace('滋賀', '25').replace('京都', '26').replace('大阪', '27').replace('兵庫', '28').replace('奈良', '29').replace('和歌山', '30').replace('鳥取', '31').replace('島根', '32').replace('岡山', '33').replace('広島', '34').replace('山口', '35').replace('徳島', '36').replace('香川', '37').replace('愛媛', '38').replace('高知', '39').replace('福岡', '40').replace('佐賀', '41').replace('長崎', '42').replace('熊本', '43').replace('大分', '44').replace('宮崎', '45').replace('鹿児島', '46').replace('沖縄', '47')\n",
    "            rows[9] = rows[9].replace('S1', '5').replace('S2', '4').replace('A1', '3').replace('A2', '2').replace('A3', '1')\n",
    "            rows[10] = rows[10].replace('両', '1').replace('逃', '2').replace('追', '3')\n",
    "\n",
    "            car_num = rows[4]\n",
    "            result = race_result.index(car_num) + 1\n",
    "            rows.append(result)\n",
    "\n",
    "            rows.insert(0, kaisaidate)\n",
    "            rows.insert(1, place)\n",
    "            rows.insert(2, race_num)\n",
    "\n",
    "            #print(rows)\n",
    "\n",
    "            with open(filename, \"a\") as f:\n",
    "                    writer = csv.writer(f, lineterminator='\\n') # 改行コード（\\n）を指定しておく\n",
    "                    writer.writerow(rows)     # list（1次元配列）の場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait 1 seconds before access url\n",
    "sleep_time = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_places(): # get places\n",
    "    places = []\n",
    "    home_url = 'https://keirin.kdreams.jp'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(home_url, headers=headers)# <Response [200]>\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    stadiums = soup.find(\"div\", class_=\"stadium_nav_list\").find_all(\"dl\", class_=\"stadium\")\n",
    "    for stadium in stadiums:\n",
    "        links = stadium.find_all(\"a\")\n",
    "        for link in links:\n",
    "            place = link.get(\"href\").split(\"/\")[-2]\n",
    "            places.append(place)\n",
    "            \n",
    "    return places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_file(date):\n",
    "\n",
    "    filename = \"predict/\" + date.strftime(\"%Y%m\") + \"_data.csv\"\n",
    "    \n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    \n",
    "    csv_header = [''] * 30\n",
    "    csv_header[0] = 'date'\n",
    "    csv_header[1] = 'place'\n",
    "    csv_header[2] = 'race_num'\n",
    "    csv_header[3] = 'predict'\n",
    "    csv_header[4] = 'koukiai'\n",
    "    csv_header[5] = 'evaluation'\n",
    "    csv_header[6] = 'bracket'\n",
    "    csv_header[7] = 'car_num'\n",
    "    csv_header[8] = 'name'\n",
    "    csv_header[9] = 'prefecture'\n",
    "    csv_header[10] = 'age'\n",
    "    csv_header[11] = 'period'\n",
    "    csv_header[12] = 'rank'\n",
    "    csv_header[13] = 'leg'\n",
    "    csv_header[14] = 'gear'\n",
    "    csv_header[15] = 'racing piont'\n",
    "    csv_header[16] = 'S'\n",
    "    csv_header[17] = 'B'\n",
    "    csv_header[18] = 'Nige'\n",
    "    csv_header[19] = 'Maki'\n",
    "    csv_header[20] = 'Sashi'\n",
    "    csv_header[21] = 'Ma'\n",
    "    csv_header[22] = '1st'\n",
    "    csv_header[23] = '2nd'\n",
    "    csv_header[24] = '3rd'\n",
    "    csv_header[25] = 'Chakugai'\n",
    "    csv_header[26] = 'win'\n",
    "    csv_header[27] = '2ren'\n",
    "    csv_header[28] = '3ren'\n",
    "    csv_header[29] = 'result'\n",
    "\n",
    "    with open(filename, \"a\") as f:\n",
    "            writer = csv.writer(f, lineterminator='\\n') # 改行コード（\\n）を指定しておく\n",
    "            writer.writerow(csv_header)   # list（1次元配列）の場合\n",
    "            \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hakodate', 'aomori', 'iwakitaira', 'yahiko', 'maebashi', 'toride', 'utsunomiya', 'omiya', 'seibuen', 'keiokaku', 'tachikawa', 'matsudo', 'chiba', 'kawasaki', 'hiratsuka', 'odawara', 'ito', 'shizuoka', 'nagoya', 'gifu', 'ogaki', 'toyohashi', 'toyama', 'matsusaka', 'yokkaichi', 'fukui', 'nara', 'mukomachi', 'wakayama', 'kishiwada', 'tamano', 'hiroshima', 'hofu', 'takamatsu', 'komatsushima', 'kochi', 'matsuyama', 'kokura', 'kurume', 'takeo', 'sasebo', 'beppu', 'kumamoto']\n"
     ]
    }
   ],
   "source": [
    "places = get_places()\n",
    "print(places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://keirin.kdreams.jp/hakodate/schedule/2018/09\n",
      "https://keirin.kdreams.jp/hakodate/raceresult/11201809030100/\n",
      "https://keirin.kdreams.jp/hakodate/racedetail/1120180903010001/?l-id=l-pc-srri-srdi-raceinfo_kaisai_detail_info_nav_btn\n",
      "RACE RESULT 20180903 hakodate 1\n",
      "['7', '3', '1', '5', '4', '2', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 hakodate 2\n",
      "['3', '2', '7', '1', '5', '6', '4']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 hakodate 3\n",
      "['2', '3', '1', '5', '7', '6', '4']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 hakodate 4\n",
      "['5', '1', '4', '3', '7', '2', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 hakodate 5\n",
      "['3', '7', '1', '4', '5', '2', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 hakodate 6\n",
      "['2', '8', '7', '1', '3', '5', '9', '6', '4']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 hakodate 7\n",
      "['2', '3', '7', '9', '5', '6', '8', '4', '1']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 hakodate 8\n",
      "['5', '2', '1', '7', '9', '8', '3', '6', '4']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 hakodate 9\n",
      "['5', '3', '9', '2', '6', '1', '8', '7', '4']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 hakodate 10\n",
      "['5', '1', '4', '2', '6', '3', '8', '9', '7']\n",
      "RACE RECORD\n",
      "https://keirin.kdreams.jp/hakodate/racedetail/1120180903020001/?l-id=l-pc-srdi-srdi-raceinfo_kaisai_detail_info_nav_btn\n",
      "RACE RESULT 20180904 hakodate 1\n",
      "['5', '2', '6', '1', '3', '7', '4']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 hakodate 2\n",
      "['3', '7', '1', '2', '4', '5', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 hakodate 3\n",
      "['5', '4', '1', '6', '2', '3', '7']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 hakodate 4\n",
      "['5', '6', '3', '4', '2', '1', '7']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 hakodate 5\n",
      "['5', '4', '1', '3', '2', '7', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 hakodate 6\n",
      "['1', '4', '6', '9', '7', '2', '8', '5', '3']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 hakodate 7\n",
      "['3', '4', '1', '8', '7', '2', '9', '6', '5']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 hakodate 8\n",
      "['1', '4', '9', '7', '2', '3', '8', '5', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 hakodate 9\n",
      "['1', '2', '7', '8', '9', '3', '5', '6', '4']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 hakodate 10\n",
      "['1', '9', '3', '4', '6', '2', '7', '8', '5']\n",
      "RACE RECORD\n",
      "https://keirin.kdreams.jp/hakodate/racedetail/1120180903030001/?l-id=l-pc-srdi-srdi-raceinfo_kaisai_detail_info_nav_btn\n",
      "RACE RESULT 20180905 hakodate 1\n",
      "['3', '6', '1', '5', '4', '7', '2']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180905 hakodate 2\n",
      "['1', '2', '6', '5', '4', '7', '3']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180905 hakodate 3\n",
      "['5', '1', '2', '7', '3', '4', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180905 hakodate 4\n",
      "['7', '2', '5', '3', '1', '4', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180905 hakodate 5\n",
      "['4', '6', '1', '9', '2', '8', '3', '5', '7']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180905 hakodate 6\n",
      "['2', '9', '7', '8', '6', '1', '3', '4', '5']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180905 hakodate 7\n",
      "['3', '1', '5', '2', '7', '4', '9', '6', '8']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180905 hakodate 8\n",
      "['1', '7', '9', '3', '5', '6', '8', '4', '2']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180905 hakodate 9\n",
      "['2', '3', '1', '7', '5', '4', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180905 hakodate 10\n",
      "['2', '7', '6', '9', '5', '3', '4', '1', '8']\n",
      "RACE RECORD\n",
      "javascript:void(0)\n",
      "Response error: javascript:void(0)\n",
      "javascript:void(0)\n",
      "Response error: javascript:void(0)\n",
      "https://keirin.kdreams.jp/raceresult/\n",
      "No races\n",
      "https://keirin.kdreams.jp/aomori/schedule/2018/09\n",
      "https://keirin.kdreams.jp/aomori/raceresult/12201809020100/\n",
      "https://keirin.kdreams.jp/aomori/racedetail/1220180902010001/?l-id=l-pc-srri-srdi-raceinfo_kaisai_detail_info_nav_btn\n",
      "RACE RESULT 20180902 aomori 1\n",
      "['7', '3', '1', '4', '5', '2', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180902 aomori 2\n",
      "['5', '3', '4', '1', '7', '2', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180902 aomori 3\n",
      "['4', '1', '2', '5', '3', '6', '7']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180902 aomori 4\n",
      "['2', '5', '7', '4', '3', '1', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180902 aomori 5\n",
      "['2', '4', '3', '7', '5', '1', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180902 aomori 6\n",
      "['4', '5', '2', '3', '1', '6', '7']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180902 aomori 7\n",
      "['1', '2', '4', '5', '7', '3', '6']\n",
      "RACE RECORD\n",
      "https://keirin.kdreams.jp/aomori/racedetail/1220180902020001/?l-id=l-pc-srdi-srdi-raceinfo_kaisai_detail_info_nav_btn\n",
      "RACE RESULT 20180903 aomori 1\n",
      "['3', '1', '4', '2', '5', '7', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 aomori 2\n",
      "['5', '4', '2', '1', '6', '7', '3']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 aomori 3\n",
      "['1', '7', '6', '4', '2', '5', '3']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 aomori 4\n",
      "['7', '1', '2', '4', '6', '5', '3']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 aomori 5\n",
      "['7', '4', '1', '5', '2', '3', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 aomori 6\n",
      "['5', '3', '4', '1', '2', '7', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180903 aomori 7\n",
      "['1', '4', '7', '2', '5', '3', '6']\n",
      "RACE RECORD\n",
      "https://keirin.kdreams.jp/aomori/racedetail/1220180902030001/?l-id=l-pc-srdi-srdi-raceinfo_kaisai_detail_info_nav_btn\n",
      "RACE RESULT 20180904 aomori 1\n",
      "['4', '2', '5', '1', '3', '7', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 aomori 2\n",
      "['4', '3', '5', '1', '7', '6', '2']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 aomori 3\n",
      "['4', '3', '5', '6', '1', '2', '7']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 aomori 4\n",
      "['2', '3', '4', '5', '1', '7', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 aomori 5\n",
      "['1', '3', '7', '4', '2', '5', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180904 aomori 6\n",
      "['1', '5', '3', '2', '6', '7', '4']\n",
      "RACE RECORD\n",
      "https://keirin.kdreams.jp/aomori/raceresult/12201809180100/\n",
      "https://keirin.kdreams.jp/aomori/racedetail/1220180918010001/?l-id=l-pc-srri-srdi-raceinfo_kaisai_detail_info_nav_btn\n",
      "RACE RESULT 20180918 aomori 1\n",
      "['2', '7', '3', '5', '6', '1', '9', '4', '8']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180918 aomori 2\n",
      "['2', '3', '9', '1', '8', '5', '4', '6', '7']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180918 aomori 3\n",
      "['7', '3', '4', '5', '9', '2', '8', '1', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180918 aomori 4\n",
      "['2', '8', '9', '7', '1', '3', '5', '4', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180918 aomori 5\n",
      "['5', '1', '6', '8', '9', '4', '7', '2', '3']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180918 aomori 6\n",
      "['5', '9', '3', '6', '8', '1', '2', '7', '4']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180918 aomori 7\n",
      "['6', '3', '9', '8', '2', '7', '4', '5', '1']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180918 aomori 8\n",
      "['5', '2', '7', '3', '8', '4', '9', '1', '6']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180918 aomori 9\n",
      "['1', '9', '5', '4', '7', '6', '8', '2', '3']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180918 aomori 10\n",
      "['2', '9', '1', '7', '5', '8', '6', '3', '4']\n",
      "RACE RECORD\n",
      "RACE RESULT 20180918 aomori 11\n",
      "['6', '9', '5', '1', '7', '4', '2', '8', '3']\n",
      "RACE RECORD\n",
      "https://keirin.kdreams.jp/aomori/racedetail/1220180918020001/?l-id=l-pc-srdi-srdi-raceinfo_kaisai_detail_info_nav_btn\n",
      "RACE RESULT 20180919 aomori 1\n",
      "['6', '3', '9', '2', '1', '5', '7', '8', '4']\n",
      "RACE RECORD\n"
     ]
    }
   ],
   "source": [
    "for place in places:\n",
    "\n",
    "    today = date.today()\n",
    "    filename = init_file(today)\n",
    "\n",
    "    target_url = get_data_url(today, place)\n",
    "    print(target_url)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    time.sleep(sleep_time)\n",
    "    try:\n",
    "        response = requests.get(target_url, headers=headers)# <Response [200]>\n",
    "    except:\n",
    "        print(\"Response error:\", target_url)\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    a_results = soup.find_all(\"a\", string=\"結果\")\n",
    "    if not a_results:\n",
    "        continue\n",
    "\n",
    "    for a_result in a_results:\n",
    "        raceresult_link = a_result.get(\"href\")\n",
    "        print(raceresult_link)\n",
    "        time.sleep(sleep_time)\n",
    "        try:\n",
    "            response = requests.get(raceresult_link, headers=headers)\n",
    "        except:\n",
    "            print(\"Response error:\", raceresult_link)\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        kaisaidate_tab_bs = soup.find(\"ul\", id=\"JS_UL_KAISAI_DATE_TAB\")\n",
    "        if not kaisaidate_tab_bs:\n",
    "            print(\"No races\")\n",
    "            continue\n",
    "\n",
    "        lis = kaisaidate_tab_bs.find_all(\"li\")\n",
    "        kaisaidates = []\n",
    "        for li in lis:\n",
    "            kaisaidates.append(li.get(\"kaisaidate\"))\n",
    "\n",
    "        for kaisaidate in kaisaidates:\n",
    "            # get race detail base URL\n",
    "            racedetail_id = \"JS_DL_KAISAI_DETAIL_INFO_NAV_\" + kaisaidate\n",
    "            racedetail_a = soup.find(\"dl\", id=racedetail_id).find(\"a\", string=\"レース詳細\")\n",
    "            if not racedetail_a:\n",
    "                print(\"No rance\")\n",
    "                continue\n",
    "            else:\n",
    "                racedetail_link_base = racedetail_a.get(\"href\")\n",
    "            print(racedetail_link_base)\n",
    "\n",
    "            # get racedetail URLs of all races\n",
    "            time.sleep(sleep_time)\n",
    "            try:\n",
    "                response = requests.get(racedetail_link_base, headers=headers)\n",
    "            except:\n",
    "                print(\"Response error:\", racedetail_link_base)\n",
    "                continue\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            dl_id = \"JS_DL_KAISAI_DETAIL_RACE_NAV_\" + kaisaidate\n",
    "            a_races = soup.find(\"dl\", id=dl_id).find_all(\"a\")\n",
    "            if not a_races:\n",
    "                continue\n",
    "\n",
    "            racedetail_links = []\n",
    "            for a_race in a_races:\n",
    "                href = a_race.get(\"href\")\n",
    "                racedetail_links.append(href)\n",
    "            racedetail_links[0] = racedetail_link_base\n",
    "\n",
    "            # call function - parse racedetail URL and save racer data and result to csv file\n",
    "            parse_racedetail_to_csv(racedetail_links, kaisaidate, place, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
